
[*第一章：数据分析概论*](./)


# 1.4. 数据分析过程


数据分析可以被描述为一个由几个步骤组成的过程，在这个过程中，原始数据被转换和处理，以产生数据可视化和预测，这是基于收集的数据的数学模型。然后，数据分析只不过是一系列步骤，每个步骤在后面的步骤中都起着关键作用。因此，将数据分析规划为一个过程链，由以下几个阶段组成:
* 问题定义
* 数据提取
* 数据准备.数据清洗
* 数据准备.数据转换
* 数据勘探与可视化
* 预测建模
* 模型验证/测试
* 部署-结果的可视化和解释
* 部署-解决方案的部署

图1-1显示了数据分析涉及到的所有流程的示意图

![Figure 1-1](images/figure_1_1.png)


## 问题定义

数据分析的过程实际上早在收集原始数据之前就开始了。事实上，数据分析总是从一个需要解决的问题开始，这个问题需要定义。

问题只有在您集中您想要学习的系统之后才会定义；这可能是一个机制、一个应用程序，或者是一个一般的过程。一般来说，本研究是为了更好地了解其运作，但特别是本研究将为了能够做出预测或选择(定义为明智的选择)，必须了解其行为的原则。

科学问题或业务的定义步骤和相应的文档(交付品)都是非常重要的，以便将整个分析的重点严格地放在获得结果上。事实上，对系统进行全面或详尽的研究有时是很复杂的，而且您开始时并不总是有足够的信息。因此，问题的定义，特别是问题的规划，可以决定整个项目所遵循的指导方针。
一旦定义并记录了问题，您就可以进入数据分析的项目计划阶段了。需要进行规划，以了解哪些专业人员和资源是必要的，以满足尽可能有效地执行项目的要求。所以你要考虑这个领域的问题，包括问题的解决。您将在各个感兴趣的领域寻找专家，并安装执行数据分析所需的软件。

此外，在计划阶段，您选择一个有效的团队。一般来说，这些团队应该是跨学科的，以便通过从不同的角度看数据来解决问题。因此，建立一个好的团队无疑是导致数据分析成功的关键因素之一。

## 数据提取

一旦定义了问题，第一步就是获取数据以执行分析。数据的选择必须以建立预测模型为基本目的，因此数据的选择对分析的成功也是至关重要的。所收集的样本数据必须尽可能多地反映现实世界，即系统如何对来自现实世界的刺激作出反应。例如，如果您使用的是大量的原始数据集，而它们不能很好地收集，这些数据可能会描述虚假或不平衡的情况。

因此，对数据的糟糕选择，甚至对不完全代表系统的数据集进行分析，都将导致模型偏离所研究的系统。

数据的搜索和检索通常需要一种超越单纯的技术研究和数据提取的直觉。这个过程还需要对数据的性质和形式有仔细的了解，只有在问题应用领域有良好的经验和知识才能提供这些数据。

不管所需的数据质量和数量如何，另一个问题是使用最好的数据来源。

如果工作室环境是实验室(技术或科学)，并且生成的数据是实验性的，那么在这种情况下，数据源是很容易识别的。在这种情况下，问题将只与实验装置有关。

但是，数据分析不可能在每个应用领域都以严格的实验方式复制数据收集的系统。许多领域需要搜索周围世界的数据，通常依靠外部实验数据，甚至更多的是通过访谈或调查收集这些数据。因此，在这些情况下，找到一个能够提供数据分析所需的所有信息的良好数据源是非常困难的。通常需要从多个数据源检索数据，以弥补任何缺陷，识别任何差异，并使数据集尽可能通用。

当您想获取数据时，最好从Web开始。但是，Web上的大多数数据可能很难捕获；事实上，并非所有的数据都可以在文件或数据库中获得，但可能是HTML页面中以许多不同格式提供的内容。为此，一种叫做Web抓取的方法允许通过识别网页中HTML标记的特定出现来收集数据。有专门为此目的设计的软件，一旦发现事件，就会提取所需的数据。一旦搜索完成，您将得到一个数据列表，准备好进行数据分析。


## 数据准备

在数据分析所涉及的所有步骤中，数据准备虽然看起来问题较少，但实际上需要更多的资源和更多的时间来完成。数据通常是从不同的数据源收集的，每个数据源都有不同的表示形式和格式的数据。因此，所有这些数据都必须为数据分析过程做好准备。

数据的准备涉及到获取、清理、规范化和将数据转换成一个优化的数据集，即以一种通常是表格式的、适合于设计阶段计划的分析方法的已准备好的格式。

可能会出现许多潜在的问题，包括无效的、模糊的或缺失的值、复制的字段和超出范围的数据。

## 数据探测/可视化

探测数据本质上包括在图形或统计表示中搜索数据，以便找到模式、连接和关系。数据可视化是突出可能的模式的最佳工具。

近年来，数据可视化技术得到了很大的发展，已经成为一门真正的学科。事实上，许多技术被专门用于显示数据，许多显示类型被应用于从数据集中提取最佳信息。

数据探索包括对数据的初步审查，这对于理解收集到的信息类型及其含义非常重要。结合在定义问题期间获得的信息，这种分类将确定哪种数据分析方法最适合于得出模型定义。

一般而言，除了通过可视化数据对图表进行详细研究外，这一阶段还可能包括以下一项或多项活动：

* 汇总数据
* 分组数据
* 探测不同属性之间的关系
* 确定模式和趋势
* 构建回归模型
* 构建分类模型

一般来说，数据分析需要总结关于要研究的数据的陈述。摘要是在不牺牲重要信息的情况下，将数据还原为解释的过程。

聚类是一种数据分析方法，用于查找由公共属性(也称为分组)联合的组。

分析的另一个重要步骤是确定数据中的关系、趋势和异常。为了找到这类信息，你常常不得不求助于工具以及执行另一轮的数据分析，这一次的数据可视化本身。

其他的数据挖掘方法，如决策树和关联规则，会自动从数据中提取重要的事实或规则。这些方法可与数据可视化并行使用，以揭示数据之间的关系。

## 预测建模

预测建模是一个用于数据分析的过程，用来建立或选择一个合适的统计模型来预测结果的概率。

在研究了数据之后，您就拥有了开发编码数据之间关系的数学模型所需的所有信息。这些模型对于理解所研究的系统是有用的，并以一种特定的方式用于两个主要目的。第一种方法是对系统产生的数据值进行预测；在本例中，您将处理回归模型。第二个目的是对新的数据产品进行分类，在本例中，您将使用分类模型或聚类模型。事实上，可以根据模型产生的结果类型来划分：

* 分类模型：如果由模型类型得到的结果是绝对的。
* 回归模型：如果模型类型得到的结果是数字的。
* 聚类模型：如果模型类型获得的结果是描述性的。
生成这些模型的简单方法包括线性回归、Logistic回归、分类和回归树以及k近邻等技术。但是分析的方法很多，而且每种方法都有其独特的特点，这使得它对于某些类型的数据和分析来说是很好的。这些方法中的每一种都会产生特定的模型，然后它们的选择与产品模型的性质有关。

其中一些模型将根据其结构提供与实际系统相对应的值。他们将以一种简单和明确的方式解释正在研究的制度的一些特点。其他模型将继续给出很好的预测，但它们的结构将仅仅是一个`黑匣子`，其解释系统特性的能力有限。

## 模型验证

模型的验证(即测试阶段)是一个重要的阶段，它允许您在开始数据的基础上验证构建的模型。这很重要，因为它允许您通过直接将模型生成的数据与实际系统进行比较来评估模型生成的数据的有效性。但这一次，你从一组开始的数据中走出来，整个分析都建立在这些数据上。

通常，当您使用数据来构建模型时，您会将数据作为培训集来引用，当您使用数据来验证模型时，您将它们作为验证集。

因此，通过将模型生成的数据与系统生成的数据进行比较，您将能够评估错误，并且使用不同的测试数据集，您可以估计生成模型的有效性限制。事实上，正确的预测值只能在一定范围内有效，或者根据所考虑的取值范围有不同程度的匹配。

此过程允许您不仅对模型的有效性进行数值评估，而且还可以将其与任何其他现有模型进行比较。在这方面有几种技术；最著名的是交叉验证。这种技术是基于将训练集划分成不同的部分。这些部分中的每一部分都将轮流用作验证集和任何其他训练集。在这种迭代方式中，您将拥有一个日益完善的模型。

## 部署

这是分析过程的最后一步，目的是展示结果，即分析的结论。在业务环境的部署过程中，分析被转换为委托它的客户的好处。在技术或科学环境中，它被翻译成设计解决方案或科学出版物。也就是说，部署基本上包括将从数据分析中获得的结果付诸实践。

有几种方法可以部署数据分析或数据挖掘的结果。

通常，数据分析师的部署包括为管理层或要求进行分析的客户编写报告。本文将概念性地描述从数据分析中得到的结果。报告应该直接交给经理们，这样他们就能做出决定。然后，他们将把分析的结论付诸实践。

在分析师提供的文档中，将详细讨论这四个主题:
* 分析结果
* 决策部署
* 风险分析
* 衡量业务影响
当项目的结果包括生成预测模型时，这些模型可以作为独立的应用程序部署，也可以集成到其他软件中。


